{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# interactive reimport\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, logging, time\n",
    "import os.path as osp\n",
    "import torch\n",
    "from model import Model\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description = 'pytorch version of GraphSAGE')\n",
    "parser.add_argument('--data', type = str, default = 'cora')\n",
    "# parser.add_argument('--aggr_func', type = str, default = 'MEAN') # dead argmument\n",
    "parser.add_argument('--num_epochs', type = int, default = 10)\n",
    "parser.add_argument('--batch_size', type = int, default = 128)\n",
    "parser.add_argument('--seed', type = int, default = 13)\n",
    "parser.add_argument('--cuda', action = 'store_true', help = 'use CUDA')\n",
    "parser.add_argument('--num_neg_samples', type = int, default = 10) # dead argument\n",
    "parser.add_argument('--lr', type = float, default = 0.1)\n",
    "args = parser.parse_args(args=['--cuda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_neg_samples = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(data='cora', num_epochs=10, batch_size=128, seed=13, cuda=True, num_neg_samples=-1, lr=0.1, device=device(type='cuda'))"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 22:36:37,042 - INFO - Device:cuda\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "logging.basicConfig(level = logging.INFO, format = '%(asctime)s - %(levelname)s - %(mesmodel)s')\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "logging.info('Device:' + str(args.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'cora' \n",
    "attributes_file_name = osp.join('../data', data_name, 'attributes')\n",
    "labels_file_name = osp.join('../data', data_name, 'labels')\n",
    "valid_file_name = osp.join('../data', data_name, 'valid_nodes')\n",
    "\n",
    "features = np.loadtxt(attributes_file_name, dtype=np.float32)\n",
    "labels = np.loadtxt(labels_file_name, dtype=np.int64)[:,1]\n",
    "valid_all_nodes_list = np.loadtxt(valid_file_name, dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handler import update_viewed_all_nodes_and_edges, generate_whole_graph\n",
    "def load_graph(t=14):\n",
    "\tstream_edges_dir_name = osp.join('../data', data_name, 'stream_edges')\n",
    "\tviewed_all_nodes, viewed_all_edges = None, None\n",
    "\tfor tt in range(t):\n",
    "\t\tcoming_edges = np.loadtxt(osp.join(stream_edges_dir_name, str(tt)), dtype=int)\n",
    "\t\tviewed_all_nodes, viewed_all_edges = update_viewed_all_nodes_and_edges(\n",
    "\t\t\t\t\t\t\t\tcoming_edges, viewed_all_nodes, viewed_all_edges) \n",
    "\t\tgraph, valid_nodes = generate_whole_graph(viewed_all_nodes, viewed_all_edges, valid_all_nodes_list, features, labels)\n",
    "\treturn graph, valid_nodes\n",
    "\n",
    "graph, valid_nodes = load_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameter\n",
    "input_dim = graph.x.shape[1] # 1433\n",
    "hidden_dim = 64\n",
    "output_dim = len(np.unique(graph.y)) # 7\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (sage): GraphSAGE(1433, 64, num_layers=2)\n",
      "  (lin): Linear(in_features=64, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "model = Model(in_channels=input_dim, hidden_channels=hidden_dim, out_channels=output_dim, num_layers=num_layers).to(args.device)\n",
    "print(model)\n",
    "# Model optimizer, may change into adam\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = np.ones(len(graph.x), dtype=int)\n",
    "test_mask = np.zeros(len(graph.x), dtype=int)\n",
    "test_mask[valid_nodes] = 1\n",
    "train_mask -= test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1908, 800)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask.sum(), test_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.train_mask = train_mask.astype(bool)\n",
    "graph.test_mask = test_mask.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph.to(args.device, 'x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = NeighborLoader(\n",
    "\tgraph, \n",
    "\tnum_neighbors=[args.num_neg_samples] * (num_layers - 1),\n",
    "\tinput_nodes=graph.train_mask,\n",
    "\tshuffle=True,\n",
    "\tbatch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "valid_loader = NeighborLoader(\n",
    "\tcopy.copy(graph),\n",
    "\tinput_nodes = None,\n",
    "\tnum_neighbors=[-1],\n",
    "\tshuffle = False,\n",
    "\tbatch_size = args.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[181, 1433], edge_index=[2, 367], y=[181], num_nodes=181, train_mask=[181], test_mask=[181], input_id=[128], batch_size=128)\n"
     ]
    }
   ],
   "source": [
    "sampled_data = next(iter(train_loader))\n",
    "print(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True,  True, False,  True, False, False,  True,\n",
       "        False, False, False,  True, False, False, False,  True,  True,  True,\n",
       "        False, False,  True,  True, False,  True,  True, False, False,  True,\n",
       "         True, False, False,  True, False,  True, False, False,  True,  True,\n",
       "        False, False, False, False, False, False, False,  True, False,  True,\n",
       "        False, False,  True, False, False,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True, False, False, False, False,  True,  True,  True,\n",
       "        False, False, False, False, False, False, False, False,  True, False,\n",
       "        False,  True, False, False,  True,  True,  True, False, False, False,\n",
       "         True,  True, False, False, False, False, False,  True, False,  True,\n",
       "         True, False,  True, False, False, False, False, False, False,  True,\n",
       "         True, False, False, False,  True, False,  True, False, False, False,\n",
       "        False, False, False,  True, False, False, False, False,  True, False,\n",
       "        False, False,  True,  True, False, False, False,  True, False,  True,\n",
       "        False, False, False,  True, False, False, False,  True, False, False,\n",
       "        False, False, False,  True, False, False, False, False, False,  True,\n",
       "         True, False, False, False,  True, False, False, False,  True, False,\n",
       "        False])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data.test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True, False, False,  True, False,  True,  True, False,\n",
       "         True,  True,  True, False,  True,  True,  True, False, False, False,\n",
       "         True,  True, False, False,  True, False, False,  True,  True, False,\n",
       "        False,  True,  True, False,  True, False,  True,  True, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "         True,  True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True, False,  True,  True, False, False, False,  True,  True,  True,\n",
       "        False, False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "        False,  True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "        False,  True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "         True,  True, False, False,  True,  True,  True, False,  True, False,\n",
       "         True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "        False,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "         True])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data.train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.int64)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data.x.dtype, sampled_data.y.dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(model.parameters())).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "from tqdm import tqdm\n",
    "def train(epoch):\n",
    "\tmodel.train()\n",
    "\tpbar = tqdm(total=int(len(train_loader.dataset)))\n",
    "\tpbar.set_description(f'Epoch{ epoch:02d}')\n",
    "\ttotal_loss = 0\n",
    "\ttotal_correct = 0\n",
    "\ttotal_examples = 0\n",
    "\tfor batch in train_loader:\n",
    "\t\tbatch = batch.to(args.device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\ty_pred = model.forward(batch)[:batch.batch_size]\n",
    "\t\ty_true = batch.y[:batch.batch_size]\n",
    "\t\ttotal_correct += int((y_pred.argmax(dim=-1) == y_true).sum())\n",
    "\t\tloss = model.loss(batch)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\tloss = loss.data.item()\n",
    "\t\ttotal_loss += loss * batch.train_mask[:batch.batch_size].sum()\n",
    "\t\ttotal_examples += batch.train_mask[:batch.batch_size].sum()\n",
    "\t\tpbar.update(batch.batch_size)\n",
    "\tpbar.close()\n",
    "\treturn total_loss/total_examples, total_correct / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1908"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.data.train_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch01: 100%|██████████| 2708/2708 [00:00<00:00, 8436.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, Loss: 0.3096, Train accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch02: 100%|██████████| 2708/2708 [00:00<00:00, 8433.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02, Loss: 0.0041, Train accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch03: 100%|██████████| 2708/2708 [00:00<00:00, 8971.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03, Loss: 0.0019, Train accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch04: 100%|██████████| 2708/2708 [00:00<00:00, 7986.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04, Loss: 0.0012, Train accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch05: 100%|██████████| 2708/2708 [00:00<00:00, 9714.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05, Loss: 0.0009, Train accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch06: 100%|██████████| 2708/2708 [00:00<00:00, 10073.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06, Loss: 0.0007, Train accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch07: 100%|██████████| 2708/2708 [00:00<00:00, 9168.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07, Loss: 0.0005, Train accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch08: 100%|██████████| 2708/2708 [00:00<00:00, 9146.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08, Loss: 0.0004, Train accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch09: 100%|██████████| 2708/2708 [00:00<00:00, 9593.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09, Loss: 0.0004, Train accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch10: 100%|██████████| 2708/2708 [00:00<00:00, 9775.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0003, Train accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,args.num_epochs+1):\n",
    "    avg_loss, acc = train(epoch)\n",
    "    print(f'Epoch {epoch:02d}, Loss: {avg_loss:.4f}, Train accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "\tmodel.eval()\n",
    "\ty_pred = model.inference(valid_loader, args.device).argmax(dim=-1).cpu()\n",
    "\tprint(y_pred.shape)\n",
    "\ty_true = valid_loader.data.y.cpu()\n",
    "\tprint(y_true.shape)\n",
    "\tlogging.info(\"Validation Macro F1:\" +  str(np.round(f1_score(y_true[valid_loader.data.test_mask], y_pred[valid_loader.data.test_mask], average=\"macro\"), 6)))\n",
    "\tlogging.info(\"Validation Micro F1:\" +  str(np.round(f1_score(y_true[valid_loader.data.test_mask], y_pred[valid_loader.data.test_mask], average=\"micro\"), 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = valid_loader.data.y.cpu()\n",
    "y_true[valid_loader.data.test_mask].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 22:55:51,428 - INFO - Validation Macro F1:0.017123\n",
      "2023-01-14 22:55:51,432 - INFO - Validation Micro F1:0.06375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708])\n",
      "torch.Size([2708])\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
