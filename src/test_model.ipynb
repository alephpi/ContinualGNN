{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive reimport\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, logging, time\n",
    "import os.path as osp\n",
    "import torch\n",
    "from model import Model\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description = 'pytorch version of GraphSAGE')\n",
    "parser.add_argument('--data', type = str, default = 'cora')\n",
    "# parser.add_argument('--aggr_func', type = str, default = 'MEAN') # dead argmument\n",
    "parser.add_argument('--num_epochs', type = int, default = 10)\n",
    "parser.add_argument('--batch_size', type = int, default = 128)\n",
    "parser.add_argument('--seed', type = int, default = 13)\n",
    "parser.add_argument('--cuda', action = 'store_true', help = 'use CUDA')\n",
    "parser.add_argument('--num_neg_samples', type = int, default = 10) # dead argument\n",
    "parser.add_argument('--lr', type = float, default = 0.1)\n",
    "args = parser.parse_args(args=['--cuda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(data='cora', num_epochs=10, batch_size=128, seed=13, cuda=True, num_neg_samples=10, lr=0.1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 09:36:48,358 - INFO - Device:cuda\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "logging.basicConfig(level = logging.INFO, format = '%(asctime)s - %(levelname)s - %(mesmodel)s')\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "logging.info('Device:' + str(args.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'cora' \n",
    "attributes_file_name = osp.join('../data', data_name, 'attributes')\n",
    "labels_file_name = osp.join('../data', data_name, 'labels')\n",
    "valid_file_name = osp.join('../data', data_name, 'valid_nodes')\n",
    "\n",
    "features = np.loadtxt(attributes_file_name, dtype=np.float32)\n",
    "labels = np.loadtxt(labels_file_name, dtype=np.int64)[:,1]\n",
    "valid_all_nodes_list = np.loadtxt(valid_file_name, dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handler import update_viewed_all_nodes_and_edges, generate_whole_graph\n",
    "def load_graph(t=14):\n",
    "\tstream_edges_dir_name = osp.join('../data', data_name, 'stream_edges')\n",
    "\tviewed_all_nodes, viewed_all_edges = None, None\n",
    "\tfor tt in range(t):\n",
    "\t\tcoming_edges = np.loadtxt(osp.join(stream_edges_dir_name, str(tt)), dtype=int)\n",
    "\t\tviewed_all_nodes, viewed_all_edges = update_viewed_all_nodes_and_edges(\n",
    "\t\t\t\t\t\t\t\tcoming_edges, viewed_all_nodes, viewed_all_edges) \n",
    "\t\tgraph, valid_nodes = generate_whole_graph(viewed_all_nodes, viewed_all_edges, valid_all_nodes_list, features, labels)\n",
    "\treturn graph, valid_nodes\n",
    "\n",
    "graph, valid_nodes = load_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameter\n",
    "input_dim = graph.x.shape[1] # 1433\n",
    "hidden_dim = 64\n",
    "output_dim = len(np.unique(graph.y)) # 7\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (sage): GraphSAGE(1433, 64, num_layers=2)\n",
      "  (lin): Linear(in_features=64, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "model = Model(in_channels=input_dim, hidden_channels=hidden_dim, out_channels=output_dim, num_layers=num_layers).to(args.device)\n",
    "print(model)\n",
    "# Model optimizer, may change into adam\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = np.ones(len(graph.x), dtype=int)\n",
    "test_mask = np.zeros(len(graph.x), dtype=int)\n",
    "test_mask[valid_nodes] = 1\n",
    "train_mask -= test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1908, 800)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask.sum(), test_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.train_mask = train_mask\n",
    "graph.test_mask = test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], num_nodes=2708, train_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = NeighborLoader(\n",
    "\tgraph, \n",
    "\tnum_neighbors=[args.num_neg_samples] * (num_layers - 1),\n",
    "\tinput_nodes=graph.train_mask,\n",
    "\tshuffle=True,\n",
    "\tbatch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[158, 1433], edge_index=[2, 312], y=[158], num_nodes=158, train_mask=[158], test_mask=[158], input_id=[128], batch_size=128)\n"
     ]
    }
   ],
   "source": [
    "sampled_data = next(iter(train_loader))\n",
    "print(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data.test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "        1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data.train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data.x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(model.parameters())).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "from tqdm import tqdm\n",
    "def train(epoch):\n",
    "\tmodel.train()\n",
    "\tpbar = tqdm(total=int(len(train_loader.dataset)))\n",
    "\tpbar.set_description(f'Epoch{ epoch:02d}')\n",
    "\ttotal_loss = 0\n",
    "\ttotal_examples = 0\n",
    "\tfor batch in train_loader:\n",
    "\t\tbatch = batch.to(args.device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss = model.loss(batch)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\tloss = loss.data.item()\n",
    "\t\ttotal_loss += loss * batch.batch_size\n",
    "\t\ttotal_examples += batch.batch_size\n",
    "\t\t# logging.debug(str(loss.data.item()))\n",
    "\t\t# if (np.isnan(loss)):\n",
    "\t\t# \t\tlogging.error('Loss is NaN !!!')\n",
    "\t\t# \t\tsys.exit()\n",
    "\t\t\n",
    "\t\t# if epoch % 10 == 0:\n",
    "\t\t# \t\tlogging.info('Epoch: ' + str(epoch) + ' ' + str(np.round(losses / data.train_size, 6)))\n",
    "\t\tpbar.update(batch.batch_size)\n",
    "\tpbar.close()\n",
    "\treturn total_loss/total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch01: 100%|██████████| 2708/2708 [00:00<00:00, 11572.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, Loss: 0.0188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch02: 100%|██████████| 2708/2708 [00:00<00:00, 17934.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02, Loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch03: 100%|██████████| 2708/2708 [00:00<00:00, 10109.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03, Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch04: 100%|██████████| 2708/2708 [00:00<00:00, 10803.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04, Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch05: 100%|██████████| 2708/2708 [00:00<00:00, 13508.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05, Loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch06: 100%|██████████| 2708/2708 [00:00<00:00, 15241.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06, Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch07: 100%|██████████| 2708/2708 [00:00<00:00, 16282.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07, Loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch08: 100%|██████████| 2708/2708 [00:00<00:00, 15308.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08, Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch09: 100%|██████████| 2708/2708 [00:00<00:00, 16446.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09, Loss: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch10: 100%|██████████| 2708/2708 [00:00<00:00, 15910.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,11):\n",
    "    avg_loss = train(epoch)\n",
    "    print(f'Epoch {epoch:02d}, Loss: {avg_loss:.4f}')\n",
    "    # train_acc, val_acc, test_acc = test()\n",
    "    # print(f'Epoch: {epoch:02d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
    "    #       f'Test: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "\tmodel.eval()\n",
    "\tval_output = model.forward(data.valid_nodes)\n",
    "\tlogging.info(\"Validation Macro F1:\" +  str(np.round(f1_score(data.labels[data.valid_nodes], val_output.data.cpu().numpy().argmax(axis=1), average=\"macro\"), 6)))\n",
    "\tlogging.info(\"Validation Micro F1:\" +  str(np.round(f1_score(data.labels[data.valid_nodes], val_output.data.cpu().numpy().argmax(axis=1), average=\"micro\"), 6)))\n",
    "\tlogging.info(\"Average batch time:\" + str(np.round(np.mean(times), 6)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
